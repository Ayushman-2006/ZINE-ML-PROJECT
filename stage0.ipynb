{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Dataset Overview:\n",
      "   id       dur proto service state  spkts  dpkts  sbytes  dbytes       rate  \\\n",
      "0   1  0.121478   tcp       -   FIN      6      4     258     172  74.087490   \n",
      "1   2  0.649902   tcp       -   FIN     14     38     734   42014  78.473372   \n",
      "2   3  1.623129   tcp       -   FIN      8     16     364   13186  14.170161   \n",
      "3   4  1.681642   tcp     ftp   FIN     12     12     628     770  13.677108   \n",
      "4   5  0.449454   tcp       -   FIN     10      6     534     268  33.373826   \n",
      "\n",
      "   ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  \\\n",
      "0  ...                 1               1             0           0   \n",
      "1  ...                 1               2             0           0   \n",
      "2  ...                 1               3             0           0   \n",
      "3  ...                 1               3             1           1   \n",
      "4  ...                 1              40             0           0   \n",
      "\n",
      "   ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  attack_cat  \\\n",
      "0                 0           1           1                0      Normal   \n",
      "1                 0           1           6                0      Normal   \n",
      "2                 0           2           6                0      Normal   \n",
      "3                 0           2           1                0      Normal   \n",
      "4                 0           2          39                0      Normal   \n",
      "\n",
      "   label  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "3      0  \n",
      "4      0  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 257673 entries, 0 to 257672\n",
      "Data columns (total 45 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   id                 257673 non-null  int64  \n",
      " 1   dur                257673 non-null  float64\n",
      " 2   proto              257673 non-null  object \n",
      " 3   service            257673 non-null  object \n",
      " 4   state              257673 non-null  object \n",
      " 5   spkts              257673 non-null  int64  \n",
      " 6   dpkts              257673 non-null  int64  \n",
      " 7   sbytes             257673 non-null  int64  \n",
      " 8   dbytes             257673 non-null  int64  \n",
      " 9   rate               257673 non-null  float64\n",
      " 10  sttl               257673 non-null  int64  \n",
      " 11  dttl               257673 non-null  int64  \n",
      " 12  sload              257673 non-null  float64\n",
      " 13  dload              257673 non-null  float64\n",
      " 14  sloss              257673 non-null  int64  \n",
      " 15  dloss              257673 non-null  int64  \n",
      " 16  sinpkt             257673 non-null  float64\n",
      " 17  dinpkt             257673 non-null  float64\n",
      " 18  sjit               257673 non-null  float64\n",
      " 19  djit               257673 non-null  float64\n",
      " 20  swin               257673 non-null  int64  \n",
      " 21  stcpb              257673 non-null  int64  \n",
      " 22  dtcpb              257673 non-null  int64  \n",
      " 23  dwin               257673 non-null  int64  \n",
      " 24  tcprtt             257673 non-null  float64\n",
      " 25  synack             257673 non-null  float64\n",
      " 26  ackdat             257673 non-null  float64\n",
      " 27  smean              257673 non-null  int64  \n",
      " 28  dmean              257673 non-null  int64  \n",
      " 29  trans_depth        257673 non-null  int64  \n",
      " 30  response_body_len  257673 non-null  int64  \n",
      " 31  ct_srv_src         257673 non-null  int64  \n",
      " 32  ct_state_ttl       257673 non-null  int64  \n",
      " 33  ct_dst_ltm         257673 non-null  int64  \n",
      " 34  ct_src_dport_ltm   257673 non-null  int64  \n",
      " 35  ct_dst_sport_ltm   257673 non-null  int64  \n",
      " 36  ct_dst_src_ltm     257673 non-null  int64  \n",
      " 37  is_ftp_login       257673 non-null  int64  \n",
      " 38  ct_ftp_cmd         257673 non-null  int64  \n",
      " 39  ct_flw_http_mthd   257673 non-null  int64  \n",
      " 40  ct_src_ltm         257673 non-null  int64  \n",
      " 41  ct_srv_dst         257673 non-null  int64  \n",
      " 42  is_sm_ips_ports    257673 non-null  int64  \n",
      " 43  attack_cat         257673 non-null  object \n",
      " 44  label              257673 non-null  int64  \n",
      "dtypes: float64(11), int64(30), object(4)\n",
      "memory usage: 88.5+ MB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "id                   0\n",
      "dur                  0\n",
      "proto                0\n",
      "service              0\n",
      "state                0\n",
      "spkts                0\n",
      "dpkts                0\n",
      "sbytes               0\n",
      "dbytes               0\n",
      "rate                 0\n",
      "sttl                 0\n",
      "dttl                 0\n",
      "sload                0\n",
      "dload                0\n",
      "sloss                0\n",
      "dloss                0\n",
      "sinpkt               0\n",
      "dinpkt               0\n",
      "sjit                 0\n",
      "djit                 0\n",
      "swin                 0\n",
      "stcpb                0\n",
      "dtcpb                0\n",
      "dwin                 0\n",
      "tcprtt               0\n",
      "synack               0\n",
      "ackdat               0\n",
      "smean                0\n",
      "dmean                0\n",
      "trans_depth          0\n",
      "response_body_len    0\n",
      "ct_srv_src           0\n",
      "ct_state_ttl         0\n",
      "ct_dst_ltm           0\n",
      "ct_src_dport_ltm     0\n",
      "ct_dst_sport_ltm     0\n",
      "ct_dst_src_ltm       0\n",
      "is_ftp_login         0\n",
      "ct_ftp_cmd           0\n",
      "ct_flw_http_mthd     0\n",
      "ct_src_ltm           0\n",
      "ct_srv_dst           0\n",
      "is_sm_ips_ports      0\n",
      "attack_cat           0\n",
      "label                0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayushman\\AppData\\Local\\Temp\\ipykernel_6964\\3737794869.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mean(), inplace=True)\n",
      "C:\\Users\\Ayushman\\AppData\\Local\\Temp\\ipykernel_6964\\3737794869.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessed dataset saved to processed_UNSW_NB15.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Step 1: Load and Combine All Files\n",
    "# Replace with the correct paths to the downloaded CSV files\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\Ayushman\\OneDrive\\Desktop\\project zine\\UNSW_NB15_testing-set1.csv\",\n",
    "    \n",
    "    r\"C:\\Users\\Ayushman\\OneDrive\\Desktop\\project zine\\UNSW_NB15_training-set1.csv\",\n",
    "  \n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "# Read and concatenate all files\n",
    "dataframes = [pd.read_csv(file_path) for file_path in file_paths]\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Step 2: Explore the Dataset\n",
    "print(\"Combined Dataset Overview:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Step 3: Handle Missing Values\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":  # Categorical column\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    else:  # Numerical column\n",
    "        df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "# Step 4: Encode Categorical Variables\n",
    "categorical_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Step 5: Normalize Numerical Features\n",
    "numerical_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "scaler = MinMaxScaler()\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "# Step 6: Save the Combined and Preprocessed Dataset\n",
    "output_file = \"processed_UNSW_NB15.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\nPreprocessed dataset saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "         id       dur     spkts     dpkts    sbytes    dbytes      rate  \\\n",
      "0  0.000000  0.002025  0.000470  0.000363  0.000016  0.000012  0.000074   \n",
      "1  0.000006  0.010832  0.001221  0.003449  0.000049  0.002866  0.000078   \n",
      "2  0.000011  0.027052  0.000658  0.001452  0.000024  0.000900  0.000014   \n",
      "3  0.000017  0.028027  0.001033  0.001089  0.000042  0.000053  0.000014   \n",
      "4  0.000023  0.007491  0.000845  0.000545  0.000036  0.000018  0.000033   \n",
      "\n",
      "       sttl      dttl         sload  ...  state_no  attack_cat_Backdoor  \\\n",
      "0  0.988235  1.000000  2.364553e-06  ...     False                False   \n",
      "1  0.243137  0.992126  1.401989e-06  ...     False                False   \n",
      "2  0.243137  0.992126  2.625704e-07  ...     False                False   \n",
      "3  0.243137  0.992126  4.576117e-07  ...     False                False   \n",
      "4  0.996078  0.992126  1.429776e-06  ...     False                False   \n",
      "\n",
      "   attack_cat_DoS  attack_cat_Exploits  attack_cat_Fuzzers  \\\n",
      "0           False                False               False   \n",
      "1           False                False               False   \n",
      "2           False                False               False   \n",
      "3           False                False               False   \n",
      "4           False                False               False   \n",
      "\n",
      "   attack_cat_Generic  attack_cat_Normal  attack_cat_Reconnaissance  \\\n",
      "0               False               True                      False   \n",
      "1               False               True                      False   \n",
      "2               False               True                      False   \n",
      "3               False               True                      False   \n",
      "4               False               True                      False   \n",
      "\n",
      "   attack_cat_Shellcode  attack_cat_Worms  \n",
      "0                 False             False  \n",
      "1                 False             False  \n",
      "2                 False             False  \n",
      "3                 False             False  \n",
      "4                 False             False  \n",
      "\n",
      "[5 rows x 204 columns]\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 257673 entries, 0 to 257672\n",
      "Columns: 204 entries, id to attack_cat_Worms\n",
      "dtypes: bool(163), float64(41)\n",
      "memory usage: 120.7 MB\n",
      "None\n",
      "\n",
      "Descriptive Statistics:\n",
      "                  id           dur          spkts          dpkts  \\\n",
      "count  257673.000000  2.576730e+05  257673.000000  257673.000000   \n",
      "mean        0.415255  2.077859e-02       0.001764       0.001680   \n",
      "std         0.279057  9.957177e-02       0.012771       0.010164   \n",
      "min         0.000000  0.000000e+00       0.000000       0.000000   \n",
      "25%         0.183695  1.333334e-07       0.000094       0.000000   \n",
      "50%         0.367389  7.141668e-05       0.000282       0.000182   \n",
      "75%         0.632611  1.142962e-02       0.001033       0.000908   \n",
      "max         1.000000  1.000000e+00       1.000000       1.000000   \n",
      "\n",
      "              sbytes         dbytes           rate           sttl  \\\n",
      "count  257673.000000  257673.000000  257673.000000  257673.000000   \n",
      "mean        0.000596       0.000982       0.091254       0.705886   \n",
      "std         0.012105       0.009974       0.160345       0.401915   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000006       0.000000       0.000031       0.243137   \n",
      "50%         0.000035       0.000012       0.002956       0.996078   \n",
      "75%         0.000093       0.000073       0.125000       0.996078   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "                dttl          sload  ...  ct_src_dport_ltm  ct_dst_sport_ltm  \\\n",
      "count  257673.000000  257673.000000  ...     257673.000000     257673.000000   \n",
      "mean        0.333681       0.011792  ...          0.073074          0.067393   \n",
      "std         0.443945       0.031017  ...          0.140704          0.129589   \n",
      "min         0.000000       0.000000  ...          0.000000          0.000000   \n",
      "25%         0.000000       0.000002  ...          0.000000          0.000000   \n",
      "50%         0.114173       0.000124  ...          0.000000          0.000000   \n",
      "75%         0.992126       0.013360  ...          0.051724          0.044444   \n",
      "max         1.000000       1.000000  ...          1.000000          1.000000   \n",
      "\n",
      "       ct_dst_src_ltm   is_ftp_login     ct_ftp_cmd  ct_flw_http_mthd  \\\n",
      "count   257673.000000  257673.000000  257673.000000     257673.000000   \n",
      "mean         0.114421       0.003205       0.003212          0.004400   \n",
      "std          0.173762       0.029023       0.029105          0.022728   \n",
      "min          0.000000       0.000000       0.000000          0.000000   \n",
      "25%          0.000000       0.000000       0.000000          0.000000   \n",
      "50%          0.031250       0.000000       0.000000          0.000000   \n",
      "75%          0.109375       0.000000       0.000000          0.000000   \n",
      "max          1.000000       1.000000       1.000000          1.000000   \n",
      "\n",
      "          ct_src_ltm     ct_srv_dst  is_sm_ips_ports          label  \n",
      "count  257673.000000  257673.000000    257673.000000  257673.000000  \n",
      "mean        0.098306       0.133132         0.014274       0.639077  \n",
      "std         0.142310       0.178275         0.118618       0.480269  \n",
      "min         0.000000       0.000000         0.000000       0.000000  \n",
      "25%         0.016949       0.016393         0.000000       0.000000  \n",
      "50%         0.033898       0.049180         0.000000       1.000000  \n",
      "75%         0.118644       0.163934         0.000000       1.000000  \n",
      "max         1.000000       1.000000         1.000000       1.000000  \n",
      "\n",
      "[8 rows x 41 columns]\n",
      "\n",
      "Missing Values Before Imputation:\n",
      "id                           0\n",
      "dur                          0\n",
      "spkts                        0\n",
      "dpkts                        0\n",
      "sbytes                       0\n",
      "                            ..\n",
      "attack_cat_Generic           0\n",
      "attack_cat_Normal            0\n",
      "attack_cat_Reconnaissance    0\n",
      "attack_cat_Shellcode         0\n",
      "attack_cat_Worms             0\n",
      "Length: 204, dtype: int64\n",
      "\n",
      "Missing Values After Imputation:\n",
      "id                           0\n",
      "dur                          0\n",
      "spkts                        0\n",
      "dpkts                        0\n",
      "sbytes                       0\n",
      "                            ..\n",
      "attack_cat_Generic           0\n",
      "attack_cat_Normal            0\n",
      "attack_cat_Reconnaissance    0\n",
      "attack_cat_Shellcode         0\n",
      "attack_cat_Worms             0\n",
      "Length: 204, dtype: int64\n",
      "\n",
      "Categorical Columns: Index([], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayushman\\AppData\\Local\\Temp\\ipykernel_6964\\3761496436.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessed dataset saved to processed_UNSW_NB15.csv\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Step 1: Load the Dataset\n",
    "file_path = r\"C:\\Users\\Ayushman\\OneDrive\\Desktop\\project zine\\processed_UNSW_NB15.csv\"  # Replace with the combined dataset file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Explore the Dataset\n",
    "print(\"Dataset Overview:\")\n",
    "print(df.head())  # Display the first few rows\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())  # Check for column types and missing values\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(df.describe())  # Get statistical summary of numerical columns\n",
    "\n",
    "# Step 3: Handle Missing Values\n",
    "print(\"\\nMissing Values Before Imputation:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing values\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":  # For categorical columns\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    else:  # For numerical columns\n",
    "        df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "print(\"\\nMissing Values After Imputation:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Step 4: Encode Categorical Variables\n",
    "# Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "print(\"\\nCategorical Columns:\", categorical_cols)\n",
    "\n",
    "# Apply one-hot encoding to categorical variables\n",
    "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Step 5: Normalize Numerical Features\n",
    "# Identify numerical columns\n",
    "numerical_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "\n",
    "# Normalize numerical columns using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "# Step 6: Save the Preprocessed Dataset\n",
    "output_file = \"processed_UNSW_NB15.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\nPreprocessed dataset saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
